{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About the dataset\n",
    "\n",
    "The dataset contains transactions made by credit cards in September 2013 by European cardholders.\n",
    "\n",
    "This dataset presents transactions that occurred in two days, where we have 492 frauds out of 284,807 transactions. The dataset is highly unbalanced, the positive class (frauds) account for 0.172% of all transactions.\n",
    "\n",
    "It contains only numerical input variables which are the result of a PCA transformation. Unfortunately, due to confidentiality issues, we cannot provide the original features and more background information about the data. Features V1, V2, â€¦ V28 are the principal components obtained with PCA, the only features which have not been transformed with PCA are 'Time' and 'Amount'. Feature 'Time' contains the seconds elapsed between each transaction and the first transaction in the dataset. The feature 'Amount' is the transaction Amount, this feature can be used for example-dependant cost-sensitive learning. Feature 'Class' is the response variable and it takes value 1 in case of fraud and 0 otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   Time        V1        V2        V3        V4        V5        V6        V7   \n",
       " 0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599  \\\n",
       " 1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       " 2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       " 3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       " 4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       " \n",
       "          V8        V9  ...       V21       V22       V23       V24       V25   \n",
       " 0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539  \\\n",
       " 1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       " 2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       " 3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       " 4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       " \n",
       "         V26       V27       V28  Amount  Class  \n",
       " 0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       " 1  0.125895 -0.008983  0.014724    2.69      0  \n",
       " 2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       " 3 -0.221929  0.062723  0.061458  123.50      0  \n",
       " 4  0.502292  0.219422  0.215153   69.99      0  \n",
       " \n",
       " [5 rows x 31 columns],)"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"C:/Users/nikhi/OneDrive/CODE/PYTHON/Jupyter Notebook/ML PROJECTS/Credit Card Fraud Detection/creditcard.csv\")\n",
    "dataset.head(),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 31)"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      0\n",
       "V1        0\n",
       "V2        0\n",
       "V3        0\n",
       "V4        0\n",
       "V5        0\n",
       "V6        0\n",
       "V7        0\n",
       "V8        0\n",
       "V9        0\n",
       "V10       0\n",
       "V11       0\n",
       "V12       0\n",
       "V13       0\n",
       "V14       0\n",
       "V15       0\n",
       "V16       0\n",
       "V17       0\n",
       "V18       0\n",
       "V19       0\n",
       "V20       0\n",
       "V21       0\n",
       "V22       0\n",
       "V23       0\n",
       "V24       0\n",
       "V25       0\n",
       "V26       0\n",
       "V27       0\n",
       "V28       0\n",
       "Amount    0\n",
       "Class     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "legit_txns = dataset[dataset['Class']==0]\n",
    "fraud_txns = dataset[dataset['Class']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are total 284315 legit transactions representing with 0 and 492 fraud transactions representing with 1.\n"
     ]
    }
   ],
   "source": [
    "print(f\"There are total {legit_txns.shape[0]} legit transactions representing with {legit_txns['Class'].unique().item()} and {fraud_txns.shape[0]} fraud transactions representing with {fraud_txns['Class'].unique().item()}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting legit and fraud transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlUAAAGwCAYAAACAZ5AeAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAwuUlEQVR4nO3df1RU9b7/8degAoIMaCpIUmJaapIWJpKnbl65YlEdi9ZR85oZ6tLAE5I/sgy1H4eyY/4of5xzuoXn3rxZ916tIDEO/jolaaLmjxOeMgtLBymEUVRA4PtHX/ZyQpOxDw6jz8daey1mf96z93umhbza+zOfsdXV1dUJAAAAv4qPpxsAAAC4HBCqAAAADCBUAQAAGECoAgAAMIBQBQAAYAChCgAAwABCFQAAgAEtPd3AlaS2tlaHDx9WUFCQbDabp9sBAACNUFdXp+PHjys8PFw+Pue/HkWouoQOHz6siIgIT7cBAAAuwqFDh9S5c+fzjhOqLqGgoCBJP/1HsdvtHu4GAAA0htPpVEREhPV3/HwIVZdQ/S0/u91OqAIAwMtcaOoOE9UBAAAMIFQBAAAYQKgCAAAwgFAFAABgAKEKAADAAEIVAACAAYQqAAAAAwhVAAAABhCqAAAADCBUAQAAGECoAgAAMIBQBQAAYAChCgAAwABCFQAAgAGEKgAAAANaeroBmBc97a+ebgFodgpeftjTLQC4zHGlCgAAwABCFQAAgAGEKgAAAAMIVQAAAAYQqgAAAAwgVAEAABhAqAIAADCAUAUAAGAAoQoAAMAAQhUAAIABhCoAAAADCFUAAAAGEKoAAAAMIFQBAAAYQKgCAAAwgFAFAABgAKEKAADAAEIVAACAAYQqAAAAAwhVAAAABhCqAAAADCBUAQAAGECoAgAAMIBQBQAAYAChCgAAwABCFQAAgAGEKgAAAAMIVQAAAAYQqgAAAAwgVAEAABhAqAIAADCAUAUAAGAAoQoAAMAAQhUAAIABhCoAAAADCFUAAAAGEKoAAAAMIFQBAAAY4NFQlZGRoVtvvVVBQUHq2LGjhg0bpv3797vU3HnnnbLZbC7bxIkTXWqKioqUkJCggIAAdezYUdOmTdOZM2dcajZu3KhbbrlFfn5+6tatmzIzMxv0s2TJEnXp0kX+/v6KiYnRtm3bXMZPnz6t5ORkXXXVVWrTpo0SExNVXFxs5s0AAABezaOhatOmTUpOTtann36q3NxcVVdXa8iQIaqoqHCpGz9+vI4cOWJt8+bNs8ZqamqUkJCgqqoqbdmyRStWrFBmZqbS09OtmoMHDyohIUGDBg3Srl27lJqaqnHjxmndunVWzapVq5SWlqbZs2drx44d6tOnj+Lj43X06FGrZsqUKfrggw/07rvvatOmTTp8+LAeeOCBJnyHAACAt7DV1dXVebqJeiUlJerYsaM2bdqkO+64Q9JPV6r69u2rhQsXnvM5a9eu1T333KPDhw8rNDRUkrR8+XLNmDFDJSUl8vX11YwZM5Sdna29e/dazxsxYoTKysqUk5MjSYqJidGtt96q1157TZJUW1uriIgITZ48WU8++aTKy8vVoUMHrVy5Ug8++KAkqbCwUD179lR+fr4GDBjQoLfKykpVVlZaj51OpyIiIlReXi673f7r37DziJ721yY7NuCtCl5+2NMtAPBSTqdTwcHBF/z73azmVJWXl0uS2rVr57L/rbfeUvv27dW7d2/NnDlTJ0+etMby8/MVFRVlBSpJio+Pl9Pp1L59+6yauLg4l2PGx8crPz9fklRVVaWCggKXGh8fH8XFxVk1BQUFqq6udqnp0aOHrrnmGqvm5zIyMhQcHGxtERERbr8nAADAO7T0dAP1amtrlZqaqoEDB6p3797W/oceekjXXnutwsPDtXv3bs2YMUP79+/X//3f/0mSHA6HS6CSZD12OBy/WON0OnXq1CkdO3ZMNTU156wpLCy0juHr66uQkJAGNfXn+bmZM2cqLS3Nelx/pQoAAFx+mk2oSk5O1t69e/Xxxx+77J8wYYL1c1RUlDp16qTBgwfrwIEDuu666y51m27x8/OTn5+fp9sAAACXQLO4/ZeSkqKsrCxt2LBBnTt3/sXamJgYSdJXX30lSQoLC2vwCbz6x2FhYb9YY7fb1bp1a7Vv314tWrQ4Z83Zx6iqqlJZWdl5awAAwJXLo6Gqrq5OKSkpWr16tdavX6/IyMgLPmfXrl2SpE6dOkmSYmNjtWfPHpdP6eXm5sput6tXr15WTV5enstxcnNzFRsbK0ny9fVVdHS0S01tba3y8vKsmujoaLVq1cqlZv/+/SoqKrJqAADAlcujt/+Sk5O1cuVKvffeewoKCrLmJgUHB6t169Y6cOCAVq5cqbvvvltXXXWVdu/erSlTpuiOO+7QTTfdJEkaMmSIevXqpdGjR2vevHlyOByaNWuWkpOTrVtvEydO1Guvvabp06fr0Ucf1fr16/XOO+8oOzvb6iUtLU1jxoxRv3791L9/fy1cuFAVFRUaO3as1VNSUpLS0tLUrl072e12TZ48WbGxsef85B8AALiyeDRULVu2TNJPyyac7c0339QjjzwiX19f/e1vf7MCTkREhBITEzVr1iyrtkWLFsrKytKkSZMUGxurwMBAjRkzRs8++6xVExkZqezsbE2ZMkWLFi1S586d9frrrys+Pt6qGT58uEpKSpSeni6Hw6G+ffsqJyfHZfL6ggUL5OPjo8TERFVWVio+Pl5Lly5toncHAAB4k2a1TtXlrrHrXPxarFMFNMQ6VQAulleuUwUAAOCtCFUAAAAGEKoAAAAMIFQBAAAYQKgCAAAwgFAFAABgAKEKAADAAEIVAACAAYQqAAAAAwhVAAAABhCqAAAADCBUAQAAGECoAgAAMIBQBQAAYAChCgAAwABCFQAAgAGEKgAAAAMIVQAAAAYQqgAAAAwgVAEAABhAqAIAADCAUAUAAGAAoQoAAMAAQhUAAIABhCoAAAADCFUAAAAGEKoAAAAMIFQBAAAYQKgCAAAwgFAFAABgAKEKAADAAEIVAACAAYQqAAAAAwhVAAAABhCqAAAADCBUAQAAGECoAgAAMIBQBQAAYAChCgAAwABCFQAAgAGEKgAAAAMIVQAAAAYQqgAAAAwgVAEAABhAqAIAADCAUAUAAGAAoQoAAMAAQhUAAIABhCoAAAADCFUAAAAGeDRUZWRk6NZbb1VQUJA6duyoYcOGaf/+/S41p0+fVnJysq666iq1adNGiYmJKi4udqkpKipSQkKCAgIC1LFjR02bNk1nzpxxqdm4caNuueUW+fn5qVu3bsrMzGzQz5IlS9SlSxf5+/srJiZG27Ztc7sXAABwZfJoqNq0aZOSk5P16aefKjc3V9XV1RoyZIgqKiqsmilTpuiDDz7Qu+++q02bNunw4cN64IEHrPGamholJCSoqqpKW7Zs0YoVK5SZman09HSr5uDBg0pISNCgQYO0a9cupaamaty4cVq3bp1Vs2rVKqWlpWn27NnasWOH+vTpo/j4eB09erTRvQAAgCuXra6urs7TTdQrKSlRx44dtWnTJt1xxx0qLy9Xhw4dtHLlSj344IOSpMLCQvXs2VP5+fkaMGCA1q5dq3vuuUeHDx9WaGioJGn58uWaMWOGSkpK5OvrqxkzZig7O1t79+61zjVixAiVlZUpJydHkhQTE6Nbb71Vr732miSptrZWERERmjx5sp588slG9XIhTqdTwcHBKi8vl91uN/renS162l+b7NiAtyp4+WFPtwDASzX273ezmlNVXl4uSWrXrp0kqaCgQNXV1YqLi7NqevTooWuuuUb5+fmSpPz8fEVFRVmBSpLi4+PldDq1b98+q+bsY9TX1B+jqqpKBQUFLjU+Pj6Ki4uzahrTy89VVlbK6XS6bAAA4PLUbEJVbW2tUlNTNXDgQPXu3VuS5HA45Ovrq5CQEJfa0NBQORwOq+bsQFU/Xj/2SzVOp1OnTp3SDz/8oJqamnPWnH2MC/XycxkZGQoODra2iIiIRr4bAADA2zSbUJWcnKy9e/fq7bff9nQrxsycOVPl5eXWdujQIU+3BAAAmkhLTzcgSSkpKcrKytLmzZvVuXNna39YWJiqqqpUVlbmcoWouLhYYWFhVs3PP6VX/4m8s2t+/im94uJi2e12tW7dWi1atFCLFi3OWXP2MS7Uy8/5+fnJz8/PjXcCAAB4K49eqaqrq1NKSopWr16t9evXKzIy0mU8OjparVq1Ul5enrVv//79KioqUmxsrCQpNjZWe/bscfmUXm5urux2u3r16mXVnH2M+pr6Y/j6+io6Otqlpra2Vnl5eVZNY3oBAABXLo9eqUpOTtbKlSv13nvvKSgoyJqbFBwcrNatWys4OFhJSUlKS0tTu3btZLfbNXnyZMXGxlqfthsyZIh69eql0aNHa968eXI4HJo1a5aSk5Otq0QTJ07Ua6+9punTp+vRRx/V+vXr9c477yg7O9vqJS0tTWPGjFG/fv3Uv39/LVy4UBUVFRo7dqzV04V6AQAAVy6Phqply5ZJku68806X/W+++aYeeeQRSdKCBQvk4+OjxMREVVZWKj4+XkuXLrVqW7RooaysLE2aNEmxsbEKDAzUmDFj9Oyzz1o1kZGRys7O1pQpU7Ro0SJ17txZr7/+uuLj462a4cOHq6SkROnp6XI4HOrbt69ycnJcJq9fqBcAAHDlalbrVF3uWKcK8BzWqQJwsbxynSoAAABvRagCAAAwgFAFAABgAKEKAADAAEIVAACAAYQqAAAAAwhVAAAABhCqAAAADCBUAQAAGECoAgAAMIBQBQAAYAChCgAAwABCFQAAgAGEKgAAAAMIVQAAAAYQqgAAAAxwO1QVFRWprq6uwf66ujoVFRUZaQoAAMDbuB2qIiMjVVJS0mB/aWmpIiMjjTQFAADgbdwOVXV1dbLZbA32nzhxQv7+/kaaAgAA8DYtG1uYlpYmSbLZbHrmmWcUEBBgjdXU1Gjr1q3q27ev8QYBAAC8QaND1c6dOyX9dKVqz5498vX1tcZ8fX3Vp08fTZ061XyHAAAAXqDRoWrDhg2SpLFjx2rRokWy2+1N1hQAAIC3aXSoqvfmm282RR8AAABeze1QVVFRoRdffFF5eXk6evSoamtrXca//vprY80BAAB4C7dD1bhx47Rp0yaNHj1anTp1OucnAQEAAK40boeqtWvXKjs7WwMHDmyKfgAAALyS2+tUtW3bVu3atWuKXgAAALyW26HqueeeU3p6uk6ePNkU/QAAAHglt2//zZ8/XwcOHFBoaKi6dOmiVq1auYzv2LHDWHMAAADewu1QNWzYsCZoAwAAwLu5Hapmz57dFH0AAAB4NbfnVAEAAKAht69U+fj4/OLaVDU1Nb+qIQAAAG/kdqhavXq1y+Pq6mrt3LlTK1as0Ny5c401BgAA4E3cDlW//e1vG+x78MEHdeONN2rVqlVKSkoy0hgAAIA3MTanasCAAcrLyzN1OAAAAK9iJFSdOnVKixcv1tVXX23icAAAAF7H7dt/bdu2dZmoXldXp+PHjysgIED/9V//ZbQ5AAAAb+F2qFq4cKHLYx8fH3Xo0EExMTFq27atqb4AAAC8ituhasyYMU3RBwAAgFdzO1RJUllZmf7jP/5DX3zxhSTpxhtv1KOPPqrg4GCjzQEAAHgLtyeqb9++Xdddd50WLFig0tJSlZaW6pVXXtF1113HlykDAIArlttXqqZMmaL77rtPf/nLX9Sy5U9PP3PmjMaNG6fU1FRt3rzZeJMAAADNnduhavv27S6BSpJatmyp6dOnq1+/fkabAwAA8BZu3/6z2+0qKipqsP/QoUMKCgoy0hQAAIC3cTtUDR8+XElJSVq1apUOHTqkQ4cO6e2339a4ceM0cuTIpugRAACg2XP79t8f//hH2Ww2Pfzwwzpz5owkqVWrVpo0aZJefPFF4w0CAAB4A7dDla+vrxYtWqSMjAwdOHBAknTdddcpICDAeHMAAADe4qLWqZKkgIAARUVFmewFAADAa7kdqk6fPq1XX31VGzZs0NGjR1VbW+syzlpVAADgSuR2qEpKStJHH32kBx98UP3793f5cmUAAIArlduf/svKytKaNWu0bNkyzZkzR7Nnz3bZ3LF582bde++9Cg8Pl81m05o1a1zGH3nkEdlsNpdt6NChLjWlpaUaNWqU7Ha7QkJClJSUpBMnTrjU7N69W7fffrv8/f0VERGhefPmNejl3XffVY8ePeTv76+oqCh9+OGHLuN1dXVKT09Xp06d1Lp1a8XFxenLL7906/UCAIDLl9uh6uqrrza2HlVFRYX69OmjJUuWnLdm6NChOnLkiLX993//t8v4qFGjtG/fPuXm5iorK0ubN2/WhAkTrHGn06khQ4bo2muvVUFBgV5++WXNmTNHf/7zn62aLVu2aOTIkUpKStLOnTs1bNgwDRs2THv37rVq5s2bp8WLF2v58uXaunWrAgMDFR8fr9OnTxt5LwAAgHez1dXV1bnzhLVr11rh4tprrzXXiM2m1atXa9iwYda+Rx55RGVlZQ2uYNX74osv1KtXL3322WfWau45OTm6++679d133yk8PFzLli3T008/LYfDIV9fX0nSk08+qTVr1qiwsFDST2tvVVRUKCsryzr2gAED1LdvXy1fvlx1dXUKDw/XE088oalTp0qSysvLFRoaqszMTI0YMaJRr9HpdCo4OFjl5eWy2+3uvkWNFj3tr012bMBbFbz8sKdbAOClGvv32+0rVf369dPp06fVtWtXBQUFqV27di6baRs3blTHjh11ww03aNKkSfrxxx+tsfz8fIWEhLh8PU5cXJx8fHy0detWq+aOO+6wApUkxcfHa//+/Tp27JhVExcX53Le+Ph45efnS5IOHjwoh8PhUhMcHKyYmBir5lwqKyvldDpdNgAAcHlye6L6yJEj9f333+sPf/iDQkNDm3Si+tChQ/XAAw8oMjJSBw4c0FNPPaW77rpL+fn5atGihRwOhzp27OjynJYtW6pdu3ZyOBySJIfDocjISJea0NBQa6xt27ZyOBzWvrNrzj7G2c87V825ZGRkaO7cuRfxygEAgLdxO1Rt2bJF+fn56tOnT1P04+Ls22pRUVG66aabdN1112njxo0aPHhwk5//15o5c6bS0tKsx06nUxERER7sCAAANBW3b//16NFDp06daopeLqhr165q3769vvrqK0lSWFiYjh496lJz5swZlZaWKiwszKopLi52qal/fKGas8fPft65as7Fz89PdrvdZQMAAJcnt0PViy++qCeeeEIbN27Ujz/+eEnnDH333Xf68ccf1alTJ0lSbGysysrKVFBQYNWsX79etbW1iomJsWo2b96s6upqqyY3N1c33HCD2rZta9Xk5eW5nCs3N1exsbGSpMjISIWFhbnUOJ1Obd261aoBAABXNrdv/9WvE/Xz2291dXWy2Wyqqalp9LFOnDhhXXWSfpoQvmvXLmvS+9y5c5WYmKiwsDAdOHBA06dPV7du3RQfHy9J6tmzp4YOHarx48dr+fLlqq6uVkpKikaMGKHw8HBJ0kMPPaS5c+cqKSlJM2bM0N69e7Vo0SItWLDAOu/jjz+uf/mXf9H8+fOVkJCgt99+W9u3b7eWXbDZbEpNTdXzzz+v7t27KzIyUs8884zCw8NdPq0IAACuXG6Hqg0bNhg7+fbt2zVo0CDrcf38ozFjxmjZsmXavXu3VqxYobKyMoWHh2vIkCF67rnn5OfnZz3nrbfeUkpKigYPHiwfHx8lJiZq8eLF1nhwcLA++ugjJScnKzo6Wu3bt1d6errLWla33XabVq5cqVmzZumpp55S9+7dtWbNGvXu3duqmT59uioqKjRhwgSVlZXpN7/5jXJycuTv72/s/QAAAN7L7XWqcPFYpwrwHNapAnCxGvv32+0rVfVOnjypoqIiVVVVuey/6aabLvaQAAAAXsvtUFVSUqKxY8dq7dq15xx3Z04VAADA5cLtT/+lpqaqrKxMW7duVevWrZWTk6MVK1aoe/fuev/995uiRwAAgGbP7StV69ev13vvvad+/frJx8dH1157rf7t3/5NdrtdGRkZSkhIaIo+AQAAmjW3r1RVVFRYXw3Ttm1blZSUSPppxfMdO3aY7Q4AAMBLuB2qbrjhBu3fv1+S1KdPH/3pT3/S999/r+XLl1uLcgIAAFxp3L799/jjj+vIkSOSpNmzZ2vo0KF666235Ovrq8zMTNP9AQAAeAW3Q9W///u/Wz9HR0fr22+/VWFhoa655hq1b9/eaHMAAADe4qLXqaoXEBCgW265xUQvAAAAXsvtOVUAAABoiFAFAABgAKEKAADAAEIVAACAARc1Ub2srEzbtm3T0aNHVVtb6zL28MN8EzwAALjyuB2qPvjgA40aNUonTpyQ3W6XzWazxmw2G6EKAABckdy+/ffEE0/o0Ucf1YkTJ1RWVqZjx45ZW2lpaVP0CAAA0Oy5Haq+//57/f73v1dAQEBT9AMAAOCV3A5V8fHx2r59e1P0AgAA4LXcnlOVkJCgadOm6R//+IeioqLUqlUrl/H77rvPWHMAAADewu1QNX78eEnSs88+22DMZrOppqbm13cFAADgZdwOVT9fQgEAAACGF/88efKkycMBAAB4DbdD1eDBg/X999832L9161b17dvXRE8AAABex+1Q5e/vr5tuukmrVq2S9NPtwDlz5uj222/X3XffbbxBAAAAb+D2nKrs7GwtWbJEjz76qN577z198803+vbbb5WVlaUhQ4Y0RY8AAADN3kV9919ycrK+++47vfTSS2rZsqU2btyo2267zXRvAAAAXsPt23/Hjh1TYmKili1bpj/96U/63e9+pyFDhmjp0qVN0R8AAIBXcPtKVe/evRUZGamdO3cqMjJS48eP16pVq/TYY48pOztb2dnZTdEnAABAs+b2laqJEydq8+bNioyMtPYNHz5cn3/+uaqqqow2BwAA4C0aHaqeffZZnTx5Us8884x8fBo+rXPnzsrNzTXaHAAAgLdodKiaO3euTpw40ZS9AAAAeK1Gh6q6urqm7AMAAMCruTWnymazNVUfAAAAXs2tT/9df/31FwxWpaWlv6ohAAAAb+RWqJo7d66Cg4ObqhcAAACv5VaoGjFihDp27NhUvQAAAHitRs+pYj4VAADA+fHpPwAAAAMaffuvtra2KfsAAADwam5/TQ0AAAAaIlQBAAAYQKgCAAAwgFAFAABgAKEKAADAAEIVAACAAYQqAAAAAwhVAAAABhCqAAAADCBUAQAAGECoAgAAMIBQBQAAYIBHQ9XmzZt17733Kjw8XDabTWvWrHEZr6urU3p6ujp16qTWrVsrLi5OX375pUtNaWmpRo0aJbvdrpCQECUlJenEiRMuNbt379btt98uf39/RUREaN68eQ16effdd9WjRw/5+/srKipKH374odu9AACAK5dHQ1VFRYX69OmjJUuWnHN83rx5Wrx4sZYvX66tW7cqMDBQ8fHxOn36tFUzatQo7du3T7m5ucrKytLmzZs1YcIEa9zpdGrIkCG69tprVVBQoJdffllz5szRn//8Z6tmy5YtGjlypJKSkrRz504NGzZMw4YN0969e93qBQAAXLlsdXV1dZ5uQpJsNptWr16tYcOGSfrpylB4eLieeOIJTZ06VZJUXl6u0NBQZWZmasSIEfriiy/Uq1cvffbZZ+rXr58kKScnR3fffbe+++47hYeHa9myZXr66aflcDjk6+srSXryySe1Zs0aFRYWSpKGDx+uiooKZWVlWf0MGDBAffv21fLlyxvVS2M4nU4FBwervLxcdrvdyPt2LtHT/tpkxwa8VcHLD3u6BQBeqrF/v5vtnKqDBw/K4XAoLi7O2hccHKyYmBjl5+dLkvLz8xUSEmIFKkmKi4uTj4+Ptm7datXccccdVqCSpPj4eO3fv1/Hjh2zas4+T31N/Xka08u5VFZWyul0umwAAODy1GxDlcPhkCSFhoa67A8NDbXGHA6HOnbs6DLesmVLtWvXzqXmXMc4+xznqzl7/EK9nEtGRoaCg4OtLSIi4gKvGgAAeKtmG6ouBzNnzlR5ebm1HTp0yNMtAQCAJtJsQ1VYWJgkqbi42GV/cXGxNRYWFqajR4+6jJ85c0alpaUuNec6xtnnOF/N2eMX6uVc/Pz8ZLfbXTYAAHB5arahKjIyUmFhYcrLy7P2OZ1Obd26VbGxsZKk2NhYlZWVqaCgwKpZv369amtrFRMTY9Vs3rxZ1dXVVk1ubq5uuOEGtW3b1qo5+zz1NfXnaUwvAADgyubRUHXixAnt2rVLu3btkvTThPBdu3apqKhINptNqampev755/X+++9rz549evjhhxUeHm59QrBnz54aOnSoxo8fr23btumTTz5RSkqKRowYofDwcEnSQw89JF9fXyUlJWnfvn1atWqVFi1apLS0NKuPxx9/XDk5OZo/f74KCws1Z84cbd++XSkpKZLUqF4AAMCVraUnT759+3YNGjTIelwfdMaMGaPMzExNnz5dFRUVmjBhgsrKyvSb3/xGOTk58vf3t57z1ltvKSUlRYMHD5aPj48SExO1ePFiazw4OFgfffSRkpOTFR0drfbt2ys9Pd1lLavbbrtNK1eu1KxZs/TUU0+pe/fuWrNmjXr37m3VNKYXAABw5Wo261RdCVinCvAc1qkCcLG8fp0qAAAAb0KoAgAAMIBQBQAAYAChCgAAwABCFQAAgAGEKgAAAAMIVQAAAAYQqgAAAAwgVAEAABhAqAIAADCAUAUAAGAAoQoAAMAAQhUAAIABhCoAAAADCFUAAAAGEKoAAAAMIFQBAAAYQKgCAAAwgFAFAABgAKEKAADAAEIVAACAAYQqAAAAAwhVAAAABhCqAAAADCBUAQAAGECoAgAAMIBQBQAAYAChCgAAwABCFQAAgAGEKgAAAAMIVQAAAAYQqgAAAAwgVAEAABhAqAIAADCAUAUAAGAAoQoAAMAAQhUAAIABhCoAAAADCFUAAAAGEKoAAAAMIFQBAAAYQKgCAAAwgFAFAABgAKEKAADAAEIVAACAAYQqAAAAAwhVAAAABhCqAAAADCBUAQAAGECoAgAAMIBQBQAAYECzDlVz5syRzWZz2Xr06GGNnz59WsnJybrqqqvUpk0bJSYmqri42OUYRUVFSkhIUEBAgDp27Khp06bpzJkzLjUbN27ULbfcIj8/P3Xr1k2ZmZkNelmyZIm6dOkif39/xcTEaNu2bU3ymgEAgHdq1qFKkm688UYdOXLE2j7++GNrbMqUKfrggw/07rvvatOmTTp8+LAeeOABa7ympkYJCQmqqqrSli1btGLFCmVmZio9Pd2qOXjwoBISEjRo0CDt2rVLqampGjdunNatW2fVrFq1SmlpaZo9e7Z27NihPn36KD4+XkePHr00bwIAAGj2bHV1dXWebuJ85syZozVr1mjXrl0NxsrLy9WhQwetXLlSDz74oCSpsLBQPXv2VH5+vgYMGKC1a9fqnnvu0eHDhxUaGipJWr58uWbMmKGSkhL5+vpqxowZys7O1t69e61jjxgxQmVlZcrJyZEkxcTE6NZbb9Vrr70mSaqtrVVERIQmT56sJ598stGvx+l0Kjg4WOXl5bLb7Rf7tlxQ9LS/NtmxAW9V8PLDnm4BgJdq7N/vZn+l6ssvv1R4eLi6du2qUaNGqaioSJJUUFCg6upqxcXFWbU9evTQNddco/z8fElSfn6+oqKirEAlSfHx8XI6ndq3b59Vc/Yx6mvqj1FVVaWCggKXGh8fH8XFxVk151NZWSmn0+myAQCAy1OzDlUxMTHKzMxUTk6Oli1bpoMHD+r222/X8ePH5XA45Ovrq5CQEJfnhIaGyuFwSJIcDodLoKofrx/7pRqn06lTp07phx9+UE1NzTlr6o9xPhkZGQoODra2iIgIt98DAADgHVp6uoFfctddd1k/33TTTYqJidG1116rd955R61bt/ZgZ40zc+ZMpaWlWY+dTifBCgCAy1SzvlL1cyEhIbr++uv11VdfKSwsTFVVVSorK3OpKS4uVlhYmCQpLCyswacB6x9fqMZut6t169Zq3769WrRocc6a+mOcj5+fn+x2u8sGAAAuT14Vqk6cOKEDBw6oU6dOio6OVqtWrZSXl2eN79+/X0VFRYqNjZUkxcbGas+ePS6f0svNzZXdblevXr2smrOPUV9TfwxfX19FR0e71NTW1iovL8+qAQAAaNahaurUqdq0aZO++eYbbdmyRffff79atGihkSNHKjg4WElJSUpLS9OGDRtUUFCgsWPHKjY2VgMGDJAkDRkyRL169dLo0aP1+eefa926dZo1a5aSk5Pl5+cnSZo4caK+/vprTZ8+XYWFhVq6dKneeecdTZkyxeojLS1Nf/nLX7RixQp98cUXmjRpkioqKjR27FiPvC8AAKD5adZzqr777juNHDlSP/74ozp06KDf/OY3+vTTT9WhQwdJ0oIFC+Tj46PExERVVlYqPj5eS5cutZ7fokULZWVladKkSYqNjVVgYKDGjBmjZ5991qqJjIxUdna2pkyZokWLFqlz5856/fXXFR8fb9UMHz5cJSUlSk9Pl8PhUN++fZWTk9Ng8joAALhyNet1qi43rFMFeA7rVAG4WJfNOlUAAADegFAFAABgAKEKAADAAEIVAACAAYQqAAAAAwhVAAAABhCqAAAADCBUAQAAGECoAgAAMIBQBQAAYAChCgAAwABCFQAAgAGEKgAAAAMIVQAAAAYQqgAAAAwgVAEAABhAqAIAADCAUAUAAGAAoQoAAMAAQhUAAIABhCoAAAADCFUAAAAGEKoAAAAMIFQBAAAYQKgCAAAwgFAFAABgAKEKAADAAEIVAACAAYQqAAAAAwhVAAAABhCqAAAADCBUAQAAGECoAgAAMIBQBQAAYAChCgAAwABCFQAAgAGEKgAAAAMIVQAAAAYQqgAAAAwgVAEAABhAqAIAADCAUAUAAGAAoQoAAMAAQhUAAIABhCoAAAADCFUAAAAGEKoAAAAMIFQBAAAYQKgCAAAwgFAFAABgAKEKAADAAEKVm5YsWaIuXbrI399fMTEx2rZtm6dbAgAAzQChyg2rVq1SWlqaZs+erR07dqhPnz6Kj4/X0aNHPd0aAADwMEKVG1555RWNHz9eY8eOVa9evbR8+XIFBATojTfe8HRrAADAw1p6ugFvUVVVpYKCAs2cOdPa5+Pjo7i4OOXn55/zOZWVlaqsrLQel5eXS5KcTmeT9lpTeapJjw94o6b+vbtUDr04wNMtAM1OxJOfNunx6//9qKur+8U6QlUj/fDDD6qpqVFoaKjL/tDQUBUWFp7zORkZGZo7d26D/REREU3SI4DzC351oqdbANBUMoIvyWmOHz+u4ODzn4tQ1YRmzpyptLQ063Ftba1KS0t11VVXyWazebAzXApOp1MRERE6dOiQ7Ha7p9sBYBC/31eWuro6HT9+XOHh4b9YR6hqpPbt26tFixYqLi522V9cXKywsLBzPsfPz09+fn4u+0JCQpqqRTRTdrudf3SByxS/31eOX7pCVY+J6o3k6+ur6Oho5eXlWftqa2uVl5en2NhYD3YGAACaA65UuSEtLU1jxoxRv3791L9/fy1cuFAVFRUaO3asp1sDAAAeRqhyw/Dhw1VSUqL09HQ5HA717dtXOTk5DSavA9JPt39nz57d4BYwAO/H7zfOxVZ3oc8HAgAA4IKYUwUAAGAAoQoAAMAAQhUAAIABhCrAg7p06aKFCxd6ug0AHvDII49o2LBhnm4DBhGqgF/Q1P/offbZZ5owYYL12Gazac2aNU12PgA//V7bbLYG21dffeXp1uDlWFIB8KAOHTp4ugXgijR06FC9+eabLvt+/vtYVVUlX1/fS9kWvBxXqoCLtHfvXt11111q06aNQkNDNXr0aP3www/W+PHjxzVq1CgFBgaqU6dOWrBgge68806lpqZaNWff/uvSpYsk6f7775fNZrMeAzDPz89PYWFhLtvgwYOVkpKi1NRUtW/fXvHx8ZKkV155RVFRUQoMDFRERIQee+wxnThxwjrWnDlz1LdvX5fjL1y40OV3uKamRmlpaQoJCdFVV12l6dOnixWNLj+EKuAilJWV6V//9V918803a/v27crJyVFxcbF+97vfWTVpaWn65JNP9P777ys3N1d///vftWPHjvMe87PPPpMkvfnmmzpy5Ij1GMCls2LFCvn6+uqTTz7R8uXLJUk+Pj5avHix9u3bpxUrVmj9+vWaPn26W8edP3++MjMz9cYbb+jjjz9WaWmpVq9e3RQvAR7E7T/gIrz22mu6+eab9Yc//MHa98YbbygiIkL//Oc/1alTJ61YsUIrV67U4MGDJf0Uln7pG87rbz2EhISc90u6AZiRlZWlNm3aWI/vuusuSVL37t01b948l9qfX11+/vnnNXHiRC1durTR51u4cKFmzpypBx54QJK0fPlyrVu37le8AjRHhCrgInz++efasGGDyz/K9Q4cOKBTp06purpa/fv3t/YHBwfrhhtuuJRtAjiPQYMGadmyZdbjwMBAjRw5UtHR0Q1q//a3vykjI0OFhYVyOp06c+aMTp8+rZMnTyogIOCC5yovL9eRI0cUExNj7WvZsqX69evHLcDLDKEKuAgnTpzQvffeq5deeqnBWKdOnfgUEdDMBQYGqlu3bufcf7ZvvvlG99xzjyZNmqQXXnhB7dq108cff6ykpCRVVVUpICBAPj4+DcJRdXV1k/aP5ok5VcBFuOWWW7Rv3z516dJF3bp1c9kCAwPVtWtXtWrVymVeVHl5uf75z3/+4nFbtWqlmpqapm4fQCMVFBSotrZW8+fP14ABA3T99dfr8OHDLjUdOnSQw+FwCVa7du2yfg4ODlanTp20detWa9+ZM2dUUFDQ5P3j0iJUARdQXl6uXbt2uWwTJkxQaWmpRo4cqc8++0wHDhzQunXrNHbsWNXU1CgoKEhjxozRtGnTtGHDBu3bt09JSUny8fGRzWY777m6dOmivLw8ORwOHTt27BK+SgDn0q1bN1VXV+vVV1/V119/rf/8z/+0JrDXu/POO1VSUqJ58+bpwIEDWrJkidauXetS8/jjj+vFF1/UmjVrVFhYqMcee0xlZWWX8JXgUiBUARewceNG3XzzzS7bc889p08++UQ1NTUaMmSIoqKilJqaqpCQEPn4/PRr9corryg2Nlb33HOP4uLiNHDgQPXs2VP+/v7nPdf8+fOVm5uriIgI3XzzzZfqJQI4jz59+uiVV17RSy+9pN69e+utt95SRkaGS03Pnj21dOlSLVmyRH369NG2bds0depUl5onnnhCo0eP1pgxYxQbG6ugoCDdf//9l/Kl4BKw1TFLDrgkKioqdPXVV2v+/PlKSkrydDsAAMOYqA40kZ07d6qwsFD9+/dXeXm5nn32WUnSb3/7Ww93BgBoCoQqoAn98Y9/1P79++Xr66vo6Gj9/e9/V/v27T3dFgCgCXD7DwAAwAAmqgMAABhAqAIAADCAUAUAAGAAoQoAAMAAQhUAAIABhCoAaCSbzaY1a9Z4ug0AzRShCgD+P4fDocmTJ6tr167y8/NTRESE7r33XuXl5Xm6NQBegMU/AUDSN998o4EDByokJEQvv/yyoqKiVF1drXXr1ik5OVmFhYWebhFAM8eVKgCQ9Nhjj8lms2nbtm1KTEzU9ddfrxtvvFFpaWn69NNPz/mcGTNm6Prrr1dAQIC6du2qZ555RtXV1db4559/rkGDBikoKEh2u13R0dHavn27JOnbb7/Vvffeq7Zt2yowMFA33nijPvzww0vyWgE0Da5UAbjilZaWKicnRy+88IICAwMbjIeEhJzzeUFBQcrMzFR4eLj27Nmj8ePHKygoSNOnT5ckjRo1SjfffLOWLVumFi1aaNeuXWrVqpUkKTk5WVVVVdq8ebMCAwP1j3/8Q23atGmy1wig6RGqAFzxvvrqK9XV1alHjx5uPW/WrFnWz126dNHUqVP19ttvW6GqqKhI06ZNs47bvXt3q76oqEiJiYmKioqSJHXt2vXXvgwAHsbtPwBXvIv9CtRVq1Zp4MCBCgsLU5s2bTRr1iwVFRVZ42lpaRo3bpzi4uL04osv6sCBA9bY73//ez3//PMaOHCgZs+erd27d//q1wHAswhVAK543bt3l81mc2syen5+vkaNGqW7775bWVlZ2rlzp55++mlVVVVZNXPmzNG+ffuUkJCg9evXq1evXlq9erUkady4cfr66681evRo7dmzR/369dOrr75q/LUBuHRsdRf7v2gAcBm56667tGfPHu3fv7/BvKqysjKFhITIZrNp9erVGjZsmObPn6+lS5e6XH0aN26c/ud//kdlZWXnPMfIkSNVUVGh999/v8HYzJkzlZ2dzRUrwItxpQoAJC1ZskQ1NTXq37+//vd//1dffvmlvvjiCy1evFixsbEN6rt3766ioiK9/fbbOnDggBYvXmxdhZKkU6dOKSUlRRs3btS3336rTz75RJ999pl69uwpSUpNTdW6det08OBB7dixQxs2bLDGAHgnJqoDgH6aKL5jxw698MILeuKJJ3TkyBF16NBB0dHRWrZsWYP6++67T1OmTFFKSooqKyuVkJCgZ555RnPmzJEktWjRQj/++KMefvhhFRcXq3379nrggQc0d+5cSVJNTY2Sk5P13XffyW63a+jQoVqwYMGlfMkADOP2HwAAgAHc/gMAADCAUAUAAGAAoQoAAMAAQhUAAIABhCoAAAADCFUAAAAGEKoAAAAMIFQBAAAYQKgCAAAwgFAFAABgAKEKAADAgP8HM8FNM8JHEzcAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='Class', data=dataset, order=dataset['Class'].value_counts().index)\n",
    "plt.xticks(range(len(dataset['Class'].value_counts())), ['Legit','Fraud'])\n",
    "plt.ylabel(\"Txn amount\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     492.000000\n",
       "mean      122.211321\n",
       "std       256.683288\n",
       "min         0.000000\n",
       "25%         1.000000\n",
       "50%         9.250000\n",
       "75%       105.890000\n",
       "max      2125.870000\n",
       "Name: Amount, dtype: float64"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud_txns.Amount.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    284315.000000\n",
       "mean         88.291022\n",
       "std         250.105092\n",
       "min           0.000000\n",
       "25%           5.650000\n",
       "50%          22.000000\n",
       "75%          77.050000\n",
       "max       25691.160000\n",
       "Name: Amount, dtype: float64"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "legit_txns['Amount'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 68 number of legit transactions in the dataset whose transaction amount is less than or equal to $5.65.\n"
     ]
    }
   ],
   "source": [
    "print(f\"There are {(fraud_txns[fraud_txns['Amount'] < np.percentile(fraud_txns['Amount'], 25)]).shape[0]} number of legit transactions in the dataset whose transaction amount is less than or equal to $5.65.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a highly imbalanced dataset in which one class is much more prevalent than the others. This can make it difficult for machine learning models to learn to identify the minority class, as they are often overshadowed by the majority class.\n",
    "\n",
    "There are a number of techniques that can be used to deal with highly imbalanced datasets. These include:\n",
    "\n",
    "**- Oversampling:** This involves artificially increasing the number of samples in the minority class. This can be done by duplicating existing samples or by generating new samples or by using a technique called SMOTE (Synthetic Minority Oversampling Technique).\n",
    "\n",
    "**- Undersampling:** This involves reducing the number of samples in the majority class. This can be done by randomly removing samples.\n",
    "\n",
    "**- Cost-sensitive learning:** This involves assigning different costs to misclassifications of different classes. This can help the model to focus on identifying the minority class, as misclassifications of this class are more costly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Here we're using Undersampling technique in which we're reducing the number of samples from majority class.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "legit_txns_sample = legit_txns.sample(n=492)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "legit.sample(n=492) randomly selects 492 samples from the legit_txns dataset. By doing so, it is effectively reducing the number of samples in the majority class (legit) to balance it with the number of samples in the minority class (assuming there is a minority class)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now, we have 492 legit and 492 fraud transactions.\n"
     ]
    }
   ],
   "source": [
    "print(f'Now, we have {legit_txns_sample.shape[0]} legit and {fraud_txns.shape[0]} fraud transactions.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're concatenating both datasets for training our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>94185</th>\n",
       "      <td>64772.0</td>\n",
       "      <td>-1.161723</td>\n",
       "      <td>0.202478</td>\n",
       "      <td>1.693271</td>\n",
       "      <td>-0.276490</td>\n",
       "      <td>0.842557</td>\n",
       "      <td>-1.355750</td>\n",
       "      <td>0.229176</td>\n",
       "      <td>0.118841</td>\n",
       "      <td>-0.651196</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.083887</td>\n",
       "      <td>-0.629469</td>\n",
       "      <td>0.073801</td>\n",
       "      <td>0.460505</td>\n",
       "      <td>-0.206136</td>\n",
       "      <td>-0.086076</td>\n",
       "      <td>0.008153</td>\n",
       "      <td>0.121431</td>\n",
       "      <td>1.29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138847</th>\n",
       "      <td>82880.0</td>\n",
       "      <td>-1.356602</td>\n",
       "      <td>1.555302</td>\n",
       "      <td>0.406514</td>\n",
       "      <td>-0.052373</td>\n",
       "      <td>-0.559032</td>\n",
       "      <td>-0.346228</td>\n",
       "      <td>-0.290551</td>\n",
       "      <td>1.165715</td>\n",
       "      <td>-0.554232</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.151800</td>\n",
       "      <td>-0.644118</td>\n",
       "      <td>0.131401</td>\n",
       "      <td>-0.082008</td>\n",
       "      <td>-0.221765</td>\n",
       "      <td>0.099395</td>\n",
       "      <td>0.115089</td>\n",
       "      <td>0.002685</td>\n",
       "      <td>12.57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277526</th>\n",
       "      <td>167695.0</td>\n",
       "      <td>1.885297</td>\n",
       "      <td>0.495467</td>\n",
       "      <td>-0.514183</td>\n",
       "      <td>3.909907</td>\n",
       "      <td>0.389783</td>\n",
       "      <td>0.177124</td>\n",
       "      <td>0.105277</td>\n",
       "      <td>-0.039336</td>\n",
       "      <td>-0.742316</td>\n",
       "      <td>...</td>\n",
       "      <td>0.105140</td>\n",
       "      <td>0.473838</td>\n",
       "      <td>0.162045</td>\n",
       "      <td>1.094562</td>\n",
       "      <td>0.104431</td>\n",
       "      <td>0.042470</td>\n",
       "      <td>-0.024940</td>\n",
       "      <td>-0.039349</td>\n",
       "      <td>7.56</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96630</th>\n",
       "      <td>65859.0</td>\n",
       "      <td>-0.527327</td>\n",
       "      <td>1.291105</td>\n",
       "      <td>0.963021</td>\n",
       "      <td>-0.119288</td>\n",
       "      <td>0.236783</td>\n",
       "      <td>-0.688669</td>\n",
       "      <td>0.698218</td>\n",
       "      <td>-0.029594</td>\n",
       "      <td>-0.168741</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.330228</td>\n",
       "      <td>-0.809040</td>\n",
       "      <td>-0.066726</td>\n",
       "      <td>-0.208076</td>\n",
       "      <td>-0.036445</td>\n",
       "      <td>0.110029</td>\n",
       "      <td>0.352491</td>\n",
       "      <td>0.152243</td>\n",
       "      <td>4.56</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9566</th>\n",
       "      <td>14365.0</td>\n",
       "      <td>-0.519898</td>\n",
       "      <td>0.546495</td>\n",
       "      <td>1.718019</td>\n",
       "      <td>-0.133008</td>\n",
       "      <td>0.426190</td>\n",
       "      <td>0.647543</td>\n",
       "      <td>0.005937</td>\n",
       "      <td>0.193023</td>\n",
       "      <td>1.075744</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.338922</td>\n",
       "      <td>-0.847861</td>\n",
       "      <td>-0.164876</td>\n",
       "      <td>-1.381703</td>\n",
       "      <td>-0.138877</td>\n",
       "      <td>1.050518</td>\n",
       "      <td>-0.026583</td>\n",
       "      <td>0.049700</td>\n",
       "      <td>25.36</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279863</th>\n",
       "      <td>169142.0</td>\n",
       "      <td>-1.927883</td>\n",
       "      <td>1.125653</td>\n",
       "      <td>-4.518331</td>\n",
       "      <td>1.749293</td>\n",
       "      <td>-1.566487</td>\n",
       "      <td>-2.010494</td>\n",
       "      <td>-0.882850</td>\n",
       "      <td>0.697211</td>\n",
       "      <td>-2.064945</td>\n",
       "      <td>...</td>\n",
       "      <td>0.778584</td>\n",
       "      <td>-0.319189</td>\n",
       "      <td>0.639419</td>\n",
       "      <td>-0.294885</td>\n",
       "      <td>0.537503</td>\n",
       "      <td>0.788395</td>\n",
       "      <td>0.292680</td>\n",
       "      <td>0.147968</td>\n",
       "      <td>390.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280143</th>\n",
       "      <td>169347.0</td>\n",
       "      <td>1.378559</td>\n",
       "      <td>1.289381</td>\n",
       "      <td>-5.004247</td>\n",
       "      <td>1.411850</td>\n",
       "      <td>0.442581</td>\n",
       "      <td>-1.326536</td>\n",
       "      <td>-1.413170</td>\n",
       "      <td>0.248525</td>\n",
       "      <td>-1.127396</td>\n",
       "      <td>...</td>\n",
       "      <td>0.370612</td>\n",
       "      <td>0.028234</td>\n",
       "      <td>-0.145640</td>\n",
       "      <td>-0.081049</td>\n",
       "      <td>0.521875</td>\n",
       "      <td>0.739467</td>\n",
       "      <td>0.389152</td>\n",
       "      <td>0.186637</td>\n",
       "      <td>0.76</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280149</th>\n",
       "      <td>169351.0</td>\n",
       "      <td>-0.676143</td>\n",
       "      <td>1.126366</td>\n",
       "      <td>-2.213700</td>\n",
       "      <td>0.468308</td>\n",
       "      <td>-1.120541</td>\n",
       "      <td>-0.003346</td>\n",
       "      <td>-2.234739</td>\n",
       "      <td>1.210158</td>\n",
       "      <td>-0.652250</td>\n",
       "      <td>...</td>\n",
       "      <td>0.751826</td>\n",
       "      <td>0.834108</td>\n",
       "      <td>0.190944</td>\n",
       "      <td>0.032070</td>\n",
       "      <td>-0.739695</td>\n",
       "      <td>0.471111</td>\n",
       "      <td>0.385107</td>\n",
       "      <td>0.194361</td>\n",
       "      <td>77.89</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281144</th>\n",
       "      <td>169966.0</td>\n",
       "      <td>-3.113832</td>\n",
       "      <td>0.585864</td>\n",
       "      <td>-5.399730</td>\n",
       "      <td>1.817092</td>\n",
       "      <td>-0.840618</td>\n",
       "      <td>-2.943548</td>\n",
       "      <td>-2.208002</td>\n",
       "      <td>1.058733</td>\n",
       "      <td>-1.632333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.583276</td>\n",
       "      <td>-0.269209</td>\n",
       "      <td>-0.456108</td>\n",
       "      <td>-0.183659</td>\n",
       "      <td>-0.328168</td>\n",
       "      <td>0.606116</td>\n",
       "      <td>0.884876</td>\n",
       "      <td>-0.253700</td>\n",
       "      <td>245.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281674</th>\n",
       "      <td>170348.0</td>\n",
       "      <td>1.991976</td>\n",
       "      <td>0.158476</td>\n",
       "      <td>-2.583441</td>\n",
       "      <td>0.408670</td>\n",
       "      <td>1.151147</td>\n",
       "      <td>-0.096695</td>\n",
       "      <td>0.223050</td>\n",
       "      <td>-0.068384</td>\n",
       "      <td>0.577829</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.164350</td>\n",
       "      <td>-0.295135</td>\n",
       "      <td>-0.072173</td>\n",
       "      <td>-0.450261</td>\n",
       "      <td>0.313267</td>\n",
       "      <td>-0.289617</td>\n",
       "      <td>0.002988</td>\n",
       "      <td>-0.015309</td>\n",
       "      <td>42.53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>984 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time        V1        V2        V3        V4        V5        V6   \n",
       "94185    64772.0 -1.161723  0.202478  1.693271 -0.276490  0.842557 -1.355750  \\\n",
       "138847   82880.0 -1.356602  1.555302  0.406514 -0.052373 -0.559032 -0.346228   \n",
       "277526  167695.0  1.885297  0.495467 -0.514183  3.909907  0.389783  0.177124   \n",
       "96630    65859.0 -0.527327  1.291105  0.963021 -0.119288  0.236783 -0.688669   \n",
       "9566     14365.0 -0.519898  0.546495  1.718019 -0.133008  0.426190  0.647543   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "279863  169142.0 -1.927883  1.125653 -4.518331  1.749293 -1.566487 -2.010494   \n",
       "280143  169347.0  1.378559  1.289381 -5.004247  1.411850  0.442581 -1.326536   \n",
       "280149  169351.0 -0.676143  1.126366 -2.213700  0.468308 -1.120541 -0.003346   \n",
       "281144  169966.0 -3.113832  0.585864 -5.399730  1.817092 -0.840618 -2.943548   \n",
       "281674  170348.0  1.991976  0.158476 -2.583441  0.408670  1.151147 -0.096695   \n",
       "\n",
       "              V7        V8        V9  ...       V21       V22       V23   \n",
       "94185   0.229176  0.118841 -0.651196  ... -0.083887 -0.629469  0.073801  \\\n",
       "138847 -0.290551  1.165715 -0.554232  ... -0.151800 -0.644118  0.131401   \n",
       "277526  0.105277 -0.039336 -0.742316  ...  0.105140  0.473838  0.162045   \n",
       "96630   0.698218 -0.029594 -0.168741  ... -0.330228 -0.809040 -0.066726   \n",
       "9566    0.005937  0.193023  1.075744  ... -0.338922 -0.847861 -0.164876   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "279863 -0.882850  0.697211 -2.064945  ...  0.778584 -0.319189  0.639419   \n",
       "280143 -1.413170  0.248525 -1.127396  ...  0.370612  0.028234 -0.145640   \n",
       "280149 -2.234739  1.210158 -0.652250  ...  0.751826  0.834108  0.190944   \n",
       "281144 -2.208002  1.058733 -1.632333  ...  0.583276 -0.269209 -0.456108   \n",
       "281674  0.223050 -0.068384  0.577829  ... -0.164350 -0.295135 -0.072173   \n",
       "\n",
       "             V24       V25       V26       V27       V28  Amount  Class  \n",
       "94185   0.460505 -0.206136 -0.086076  0.008153  0.121431    1.29      0  \n",
       "138847 -0.082008 -0.221765  0.099395  0.115089  0.002685   12.57      0  \n",
       "277526  1.094562  0.104431  0.042470 -0.024940 -0.039349    7.56      0  \n",
       "96630  -0.208076 -0.036445  0.110029  0.352491  0.152243    4.56      0  \n",
       "9566   -1.381703 -0.138877  1.050518 -0.026583  0.049700   25.36      0  \n",
       "...          ...       ...       ...       ...       ...     ...    ...  \n",
       "279863 -0.294885  0.537503  0.788395  0.292680  0.147968  390.00      1  \n",
       "280143 -0.081049  0.521875  0.739467  0.389152  0.186637    0.76      1  \n",
       "280149  0.032070 -0.739695  0.471111  0.385107  0.194361   77.89      1  \n",
       "281144 -0.183659 -0.328168  0.606116  0.884876 -0.253700  245.00      1  \n",
       "281674 -0.450261  0.313267 -0.289617  0.002988 -0.015309   42.53      1  \n",
       "\n",
       "[984 rows x 31 columns]"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dataset = pd.concat([legit_txns_sample, fraud_txns], axis=0)\n",
    "new_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separating Features and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = new_dataset.drop(columns='Class', axis=1)\n",
    "y = new_dataset['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>94185</th>\n",
       "      <td>64772.0</td>\n",
       "      <td>-1.161723</td>\n",
       "      <td>0.202478</td>\n",
       "      <td>1.693271</td>\n",
       "      <td>-0.276490</td>\n",
       "      <td>0.842557</td>\n",
       "      <td>-1.355750</td>\n",
       "      <td>0.229176</td>\n",
       "      <td>0.118841</td>\n",
       "      <td>-0.651196</td>\n",
       "      <td>...</td>\n",
       "      <td>0.057058</td>\n",
       "      <td>-0.083887</td>\n",
       "      <td>-0.629469</td>\n",
       "      <td>0.073801</td>\n",
       "      <td>0.460505</td>\n",
       "      <td>-0.206136</td>\n",
       "      <td>-0.086076</td>\n",
       "      <td>0.008153</td>\n",
       "      <td>0.121431</td>\n",
       "      <td>1.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138847</th>\n",
       "      <td>82880.0</td>\n",
       "      <td>-1.356602</td>\n",
       "      <td>1.555302</td>\n",
       "      <td>0.406514</td>\n",
       "      <td>-0.052373</td>\n",
       "      <td>-0.559032</td>\n",
       "      <td>-0.346228</td>\n",
       "      <td>-0.290551</td>\n",
       "      <td>1.165715</td>\n",
       "      <td>-0.554232</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108875</td>\n",
       "      <td>-0.151800</td>\n",
       "      <td>-0.644118</td>\n",
       "      <td>0.131401</td>\n",
       "      <td>-0.082008</td>\n",
       "      <td>-0.221765</td>\n",
       "      <td>0.099395</td>\n",
       "      <td>0.115089</td>\n",
       "      <td>0.002685</td>\n",
       "      <td>12.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277526</th>\n",
       "      <td>167695.0</td>\n",
       "      <td>1.885297</td>\n",
       "      <td>0.495467</td>\n",
       "      <td>-0.514183</td>\n",
       "      <td>3.909907</td>\n",
       "      <td>0.389783</td>\n",
       "      <td>0.177124</td>\n",
       "      <td>0.105277</td>\n",
       "      <td>-0.039336</td>\n",
       "      <td>-0.742316</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.266366</td>\n",
       "      <td>0.105140</td>\n",
       "      <td>0.473838</td>\n",
       "      <td>0.162045</td>\n",
       "      <td>1.094562</td>\n",
       "      <td>0.104431</td>\n",
       "      <td>0.042470</td>\n",
       "      <td>-0.024940</td>\n",
       "      <td>-0.039349</td>\n",
       "      <td>7.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96630</th>\n",
       "      <td>65859.0</td>\n",
       "      <td>-0.527327</td>\n",
       "      <td>1.291105</td>\n",
       "      <td>0.963021</td>\n",
       "      <td>-0.119288</td>\n",
       "      <td>0.236783</td>\n",
       "      <td>-0.688669</td>\n",
       "      <td>0.698218</td>\n",
       "      <td>-0.029594</td>\n",
       "      <td>-0.168741</td>\n",
       "      <td>...</td>\n",
       "      <td>0.256285</td>\n",
       "      <td>-0.330228</td>\n",
       "      <td>-0.809040</td>\n",
       "      <td>-0.066726</td>\n",
       "      <td>-0.208076</td>\n",
       "      <td>-0.036445</td>\n",
       "      <td>0.110029</td>\n",
       "      <td>0.352491</td>\n",
       "      <td>0.152243</td>\n",
       "      <td>4.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9566</th>\n",
       "      <td>14365.0</td>\n",
       "      <td>-0.519898</td>\n",
       "      <td>0.546495</td>\n",
       "      <td>1.718019</td>\n",
       "      <td>-0.133008</td>\n",
       "      <td>0.426190</td>\n",
       "      <td>0.647543</td>\n",
       "      <td>0.005937</td>\n",
       "      <td>0.193023</td>\n",
       "      <td>1.075744</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142039</td>\n",
       "      <td>-0.338922</td>\n",
       "      <td>-0.847861</td>\n",
       "      <td>-0.164876</td>\n",
       "      <td>-1.381703</td>\n",
       "      <td>-0.138877</td>\n",
       "      <td>1.050518</td>\n",
       "      <td>-0.026583</td>\n",
       "      <td>0.049700</td>\n",
       "      <td>25.36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time        V1        V2        V3        V4        V5        V6   \n",
       "94185    64772.0 -1.161723  0.202478  1.693271 -0.276490  0.842557 -1.355750  \\\n",
       "138847   82880.0 -1.356602  1.555302  0.406514 -0.052373 -0.559032 -0.346228   \n",
       "277526  167695.0  1.885297  0.495467 -0.514183  3.909907  0.389783  0.177124   \n",
       "96630    65859.0 -0.527327  1.291105  0.963021 -0.119288  0.236783 -0.688669   \n",
       "9566     14365.0 -0.519898  0.546495  1.718019 -0.133008  0.426190  0.647543   \n",
       "\n",
       "              V7        V8        V9  ...       V20       V21       V22   \n",
       "94185   0.229176  0.118841 -0.651196  ...  0.057058 -0.083887 -0.629469  \\\n",
       "138847 -0.290551  1.165715 -0.554232  ... -0.108875 -0.151800 -0.644118   \n",
       "277526  0.105277 -0.039336 -0.742316  ... -0.266366  0.105140  0.473838   \n",
       "96630   0.698218 -0.029594 -0.168741  ...  0.256285 -0.330228 -0.809040   \n",
       "9566    0.005937  0.193023  1.075744  ...  0.142039 -0.338922 -0.847861   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28  Amount  \n",
       "94185   0.073801  0.460505 -0.206136 -0.086076  0.008153  0.121431    1.29  \n",
       "138847  0.131401 -0.082008 -0.221765  0.099395  0.115089  0.002685   12.57  \n",
       "277526  0.162045  1.094562  0.104431  0.042470 -0.024940 -0.039349    7.56  \n",
       "96630  -0.066726 -0.208076 -0.036445  0.110029  0.352491  0.152243    4.56  \n",
       "9566   -0.164876 -1.381703 -0.138877  1.050518 -0.026583  0.049700   25.36  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94185     0\n",
       "138847    0\n",
       "277526    0\n",
       "96630     0\n",
       "9566      0\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Training and Testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100623</th>\n",
       "      <td>67571.0</td>\n",
       "      <td>-0.758469</td>\n",
       "      <td>-0.045410</td>\n",
       "      <td>-0.168438</td>\n",
       "      <td>-1.313275</td>\n",
       "      <td>-1.901763</td>\n",
       "      <td>0.739433</td>\n",
       "      <td>3.071892</td>\n",
       "      <td>-0.483422</td>\n",
       "      <td>0.618203</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.032500</td>\n",
       "      <td>0.042619</td>\n",
       "      <td>0.397224</td>\n",
       "      <td>0.072229</td>\n",
       "      <td>-0.242276</td>\n",
       "      <td>0.560916</td>\n",
       "      <td>-0.540955</td>\n",
       "      <td>0.150606</td>\n",
       "      <td>-0.117140</td>\n",
       "      <td>549.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247892</th>\n",
       "      <td>153727.0</td>\n",
       "      <td>-1.155463</td>\n",
       "      <td>-0.063567</td>\n",
       "      <td>1.787055</td>\n",
       "      <td>-2.525243</td>\n",
       "      <td>-0.326768</td>\n",
       "      <td>1.949911</td>\n",
       "      <td>-0.830302</td>\n",
       "      <td>0.765810</td>\n",
       "      <td>0.926058</td>\n",
       "      <td>...</td>\n",
       "      <td>0.391079</td>\n",
       "      <td>0.124634</td>\n",
       "      <td>1.073392</td>\n",
       "      <td>-0.144365</td>\n",
       "      <td>-1.432843</td>\n",
       "      <td>-0.397355</td>\n",
       "      <td>-0.198558</td>\n",
       "      <td>0.621663</td>\n",
       "      <td>0.153941</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120987</th>\n",
       "      <td>76036.0</td>\n",
       "      <td>-0.655476</td>\n",
       "      <td>1.373978</td>\n",
       "      <td>1.221612</td>\n",
       "      <td>0.840904</td>\n",
       "      <td>0.027613</td>\n",
       "      <td>-0.236808</td>\n",
       "      <td>0.342512</td>\n",
       "      <td>0.380338</td>\n",
       "      <td>-0.986734</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.060091</td>\n",
       "      <td>0.143627</td>\n",
       "      <td>0.408524</td>\n",
       "      <td>-0.075513</td>\n",
       "      <td>0.107222</td>\n",
       "      <td>-0.252732</td>\n",
       "      <td>-0.388729</td>\n",
       "      <td>0.062786</td>\n",
       "      <td>0.085067</td>\n",
       "      <td>2.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180056</th>\n",
       "      <td>124358.0</td>\n",
       "      <td>-1.556966</td>\n",
       "      <td>1.205238</td>\n",
       "      <td>-0.946492</td>\n",
       "      <td>-0.660355</td>\n",
       "      <td>1.023493</td>\n",
       "      <td>-0.873270</td>\n",
       "      <td>1.051299</td>\n",
       "      <td>-0.313142</td>\n",
       "      <td>0.742400</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.245978</td>\n",
       "      <td>-0.386318</td>\n",
       "      <td>-0.566692</td>\n",
       "      <td>0.524012</td>\n",
       "      <td>0.485989</td>\n",
       "      <td>-0.980489</td>\n",
       "      <td>-0.009384</td>\n",
       "      <td>0.097562</td>\n",
       "      <td>0.482072</td>\n",
       "      <td>20.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224830</th>\n",
       "      <td>143981.0</td>\n",
       "      <td>1.965158</td>\n",
       "      <td>-0.469675</td>\n",
       "      <td>-0.243495</td>\n",
       "      <td>0.532411</td>\n",
       "      <td>-0.863099</td>\n",
       "      <td>-0.554817</td>\n",
       "      <td>-0.663147</td>\n",
       "      <td>0.003439</td>\n",
       "      <td>1.581769</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.276215</td>\n",
       "      <td>0.191299</td>\n",
       "      <td>0.780946</td>\n",
       "      <td>0.134946</td>\n",
       "      <td>-0.008444</td>\n",
       "      <td>-0.137623</td>\n",
       "      <td>-0.207572</td>\n",
       "      <td>0.040017</td>\n",
       "      <td>-0.038413</td>\n",
       "      <td>9.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time        V1        V2        V3        V4        V5        V6   \n",
       "100623   67571.0 -0.758469 -0.045410 -0.168438 -1.313275 -1.901763  0.739433  \\\n",
       "247892  153727.0 -1.155463 -0.063567  1.787055 -2.525243 -0.326768  1.949911   \n",
       "120987   76036.0 -0.655476  1.373978  1.221612  0.840904  0.027613 -0.236808   \n",
       "180056  124358.0 -1.556966  1.205238 -0.946492 -0.660355  1.023493 -0.873270   \n",
       "224830  143981.0  1.965158 -0.469675 -0.243495  0.532411 -0.863099 -0.554817   \n",
       "\n",
       "              V7        V8        V9  ...       V20       V21       V22   \n",
       "100623  3.071892 -0.483422  0.618203  ... -0.032500  0.042619  0.397224  \\\n",
       "247892 -0.830302  0.765810  0.926058  ...  0.391079  0.124634  1.073392   \n",
       "120987  0.342512  0.380338 -0.986734  ... -0.060091  0.143627  0.408524   \n",
       "180056  1.051299 -0.313142  0.742400  ... -0.245978 -0.386318 -0.566692   \n",
       "224830 -0.663147  0.003439  1.581769  ... -0.276215  0.191299  0.780946   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28  Amount  \n",
       "100623  0.072229 -0.242276  0.560916 -0.540955  0.150606 -0.117140  549.06  \n",
       "247892 -0.144365 -1.432843 -0.397355 -0.198558  0.621663  0.153941    3.00  \n",
       "120987 -0.075513  0.107222 -0.252732 -0.388729  0.062786  0.085067    2.49  \n",
       "180056  0.524012  0.485989 -0.980489 -0.009384  0.097562  0.482072   20.90  \n",
       "224830  0.134946 -0.008444 -0.137623 -0.207572  0.040017 -0.038413    9.99  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100623    1\n",
       "247892    0\n",
       "120987    0\n",
       "180056    0\n",
       "224830    0\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction and its accuracy for training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.951715374841169\n"
     ]
    }
   ],
   "source": [
    "X_train_pred = lr.predict(X_train)\n",
    "print(accuracy_score(y_train, X_train_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction and its accuracy for testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9390862944162437\n"
     ]
    }
   ],
   "source": [
    "X_test_pred = lr.predict(X_test)\n",
    "print(accuracy_score(y_test, X_test_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
